{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zann181/Parcial-3_SyS/blob/main/Parcial_3_Dashboards_Streamlit_Ngrok_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guía Streamlit en Colab y Ngrok - Dashboards\n",
        "\n",
        "Elaborado por: Juan David Muñoz Buritica jmunozbu@unal.edu.co (Monitoria SyS 2024-1)\n",
        "Revisado: Andrés Marino Álvarez Meza amalvarezme@unal.edu.co\n",
        "\n",
        "- [Streamlit](https://streamlit.io/) es una librería destinada a crear y compartir aplicaciones o dashboards.\n",
        "- Su objetivo es ser una herramienta fácil de usar que permita ejecutar scripts directamente y desplegarlos en un aplicativo web.\n",
        "- Sin embargo, antes de ver su funcionamiento, debemos tener en cuenta que, si bien Streamlit permite correr el aplicativo, debemos alojarlo y \"hacerlo visible\" a la red.\n",
        "- Existen diferentes métodos que cumplen dicho objetivo, también dependiendo del nivel de madurez que se requiera, bien sea simplemente testeo o producción. - Una alternativa eficaz, rápida y que puede ser fácilmente escalable es [Ngrok](https://ngrok.com/)."
      ],
      "metadata": {
        "id": "mBRoMU1ZSVbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ngrok es un servicio y aplicativo globalmente distribuido que asegura, acelera y protege las aplicaciones y servicios de red.\n",
        "- En este caso, nos servirá para crear el tunel http que nos deje visualizar el dashboard corriendo con Streamlit desde el entorno del cuadernillo o script de Python.\n",
        "- El servicio gratuito de Ngrok, tras crear la cuenta tiene la posibilidad de mantener un agente activo simultáneo, cuya configuración está dada por el token de autenticación único por usuario y túnel.\n",
        "\n",
        "**Nota: Cree una cuenta en Ngrok https://ngrok.com/ con su correo UNAL y guarde el token personal asignado**"
      ],
      "metadata": {
        "id": "2y5u0IEjUUlK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AS_pGOHuRBOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c469e06-defe-4a9d-8857-f4d14eeadb63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q #instalación de librerías\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
        "!pip install soundfile #librerias descarga Youtube y manejo de audios en python"
      ],
      "metadata": {
        "id": "ilQwRjcv9azp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f81a030-3661-48c5-c030-d003751e986c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
            "  Downloading https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting brotli (from yt-dlp==2024.9.27)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting certifi (from yt-dlp==2024.9.27)\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting mutagen (from yt-dlp==2024.9.27)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pycryptodomex (from yt-dlp==2024.9.27)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting requests<3,>=2.32.2 (from yt-dlp==2024.9.27)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting urllib3<3,>=1.26.17 (from yt-dlp==2024.9.27)\n",
            "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets>=13.0 (from yt-dlp==2024.9.27)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.32.2->yt-dlp==2024.9.27)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.32.2->yt-dlp==2024.9.27)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Building wheels for collected packages: yt-dlp\n",
            "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yt-dlp: filename=yt_dlp-2024.9.27-py3-none-any.whl size=2896547 sha256=ea8b69b14e0245d9a9050f27992c1fba75b6042d90f1000e532892e8e910d374\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pw4e54bi/wheels/4c/91/d1/c5369304e2f7afb660bb6eee093af5a7d3c0ea05a3c1e8c797\n",
            "Successfully built yt-dlp\n",
            "Installing collected packages: brotli, websockets, urllib3, pycryptodomex, mutagen, idna, charset-normalizer, certifi, requests, yt-dlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.8.30\n",
            "    Uninstalling certifi-2024.8.30:\n",
            "      Successfully uninstalled certifi-2024.8.30\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "Successfully installed brotli-1.1.0 certifi-2024.8.30 charset-normalizer-3.3.2 idna-3.10 mutagen-1.47.0 pycryptodomex-3.20.0 requests-2.32.3 urllib3-2.2.3 websockets-13.1 yt-dlp-2024.9.27\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar ffmpeg si es necesario en Colab\n",
        "!apt-get install ffmpeg\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "from yt_dlp import YoutubeDL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4uDbTcaeb9b",
        "outputId": "96643c72-dc78-40d8-eb4b-33570712e7f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2--HvpXbS38V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La estructura básica para correr un programa o script en streamlit es la siguiente."
      ],
      "metadata": {
        "id": "dq3Ao2CO3x8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A continuación se muestra una app básica con algunas de las funcionalidades básicas para visualizar en dashboard.\n",
        "\n",
        "- Debemos crear un archivo .py con los códigos del dashboard para su posterior visualización en Ngrok."
      ],
      "metadata": {
        "id": "IOaX3yd226rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile parcial3_dashboard.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from numpy.fft import rfftfreq\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import freqz, bilinear, lfilter, tf2zpk\n",
        "\n",
        "import io\n",
        "import soundfile as sf\n",
        "from scipy.signal import resample, lfilter, bilinear\n",
        "from scipy.fft import rfft\n",
        "from scipy.special import softmax\n",
        "import subprocess\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "\n",
        "# Función para crear el sistema masa-resorte-amortiguador y obtener las respuestas\n",
        "def simular_sistema_masa_resorte(m, c, k):\n",
        "    # Crear la función de transferencia con scipy (numerador y denominador)\n",
        "    numerator = [1]  # El numerador es 1 en la función de transferencia dada\n",
        "    denominator = [m, c, k]  # Corresponde a ms^2 + cs + k\n",
        "\n",
        "    # Crear el sistema de función de transferencia\n",
        "    system = signal.TransferFunction(numerator, denominator)\n",
        "\n",
        "    # Generar el diagrama de Bode\n",
        "    w, mag, phase = signal.bode(system)\n",
        "\n",
        "    # Generar la respuesta al escalón\n",
        "    t_step, step_response = signal.step(system)\n",
        "\n",
        "    # Generar la respuesta al impulso\n",
        "    t_impulse, impulse_response = signal.impulse(system)\n",
        "\n",
        "    return w, mag, phase, t_step, step_response, t_impulse, impulse_response\n",
        "\n",
        "# Función para calcular los valores equivalentes del circuito RLC\n",
        "def calcular_equivalente_RLC(m, c, k):\n",
        "    L = m  # La inductancia es equivalente a la masa\n",
        "    R = c  # La resistencia es equivalente al coeficiente de amortiguamiento\n",
        "    C = 1 / k  # La capacitancia es la inversa de la constante del resorte\n",
        "    return L, R, C\n",
        "\n",
        "# Función para graficar los resultados\n",
        "def graficar_resultados(w, mag, phase, t_step, step_response, t_impulse, impulse_response):\n",
        "    # Crear las gráficas para Bode, escalón e impulso\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    # Gráfico de magnitud Bode\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.semilogx(w, mag)\n",
        "    plt.title('Diagrama de Magnitud Bode')\n",
        "    plt.xlabel('Frecuencia [rad/s]')\n",
        "    plt.ylabel('Magnitud [dB]')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Gráfico de fase Bode\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.semilogx(w, phase)\n",
        "    plt.title('Diagrama de Fase Bode')\n",
        "    plt.xlabel('Frecuencia [rad/s]')\n",
        "    plt.ylabel('Fase [grados]')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Gráfico de respuesta al escalón\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(t_step, step_response)\n",
        "    plt.title('Respuesta al Escalón')\n",
        "    plt.xlabel('Tiempo [s]')\n",
        "    plt.ylabel('Amplitud')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Gráfico de respuesta al impulso\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(t_impulse, impulse_response)\n",
        "    plt.title('Respuesta al Impulso')\n",
        "    plt.xlabel('Tiempo [s]')\n",
        "    plt.ylabel('Amplitud')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(plt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Clase para manejar la descarga de audio\n",
        "class AudioDownloader:\n",
        "    def __init__(self, link=\"https://www.youtube.com/watch?v=51cZsDsVOqc\"):\n",
        "        self.link = link\n",
        "        self.audio_mp3 = 'audio.mp3'\n",
        "        self.audio_wav = 'output.wav'\n",
        "\n",
        "    def download_audio(self):\n",
        "        \"\"\"Descarga y convierte el archivo de YouTube en formato wav\"\"\"\n",
        "        # Eliminar archivos si ya existen\n",
        "        if os.path.exists(self.audio_mp3):\n",
        "            os.remove(self.audio_mp3)\n",
        "        if os.path.exists(self.audio_wav):\n",
        "            os.remove(self.audio_wav)\n",
        "\n",
        "        st.write(\"Descargando audio desde YouTube...\")\n",
        "        subprocess.run(['yt-dlp', '--extract-audio', '-o', self.audio_mp3, '--audio-format', 'mp3', self.link], check=True)\n",
        "        subprocess.run(['ffmpeg', '-i', self.audio_mp3, self.audio_wav], check=True)\n",
        "        st.write(\"Audio descargado y convertido a formato wav.\")\n",
        "\n",
        "    def load_audio(self, target_fs=48000):\n",
        "        \"\"\"Carga el archivo de audio en formato wav y ajusta la frecuencia de muestreo si es necesario\"\"\"\n",
        "        self.x, self.fs = sf.read(self.audio_wav)\n",
        "        if len(self.x.shape) == 2:\n",
        "            self.x = np.mean(self.x, axis=1)  # Convertir estéreo a mono\n",
        "        st.write(f'Frecuencia de muestreo original: {self.fs} Hz')\n",
        "\n",
        "        # Remuestreo si la frecuencia de muestreo no es la deseada\n",
        "        if self.fs != target_fs:\n",
        "            st.write(f\"Remuestreando el audio a {target_fs} Hz...\")\n",
        "            num_samples = int(len(self.x) * target_fs / self.fs)\n",
        "            self.x = resample(self.x, num_samples)\n",
        "            self.fs = target_fs\n",
        "            st.write(f\"Remuestreo completo. Nueva frecuencia de muestreo: {self.fs} Hz\")\n",
        "\n",
        "        return self.x, self.fs\n",
        "\n",
        "    def segment_audio(self, start_time, end_time):\n",
        "        \"\"\"Segmenta el audio entre los tiempos dados\"\"\"\n",
        "        st.write(f\"Segmentando el audio de {start_time}s a {end_time}s.\")\n",
        "        x_segment = self.x[int(start_time * self.fs):int(end_time * self.fs)]\n",
        "        return x_segment, self.fs\n",
        "\n",
        "\n",
        "# Clase para cargar y reconocer el género musical\n",
        "class AudioRecognizer:\n",
        "    def __init__(self, model):\n",
        "        \"\"\"Cargar el modelo previamente cargado\"\"\"\n",
        "        self.model = model\n",
        "        self.fmax = self.model['fmax']\n",
        "        self.Xw_ = self.model['Xw_']\n",
        "        self.vf = self.model['vf']\n",
        "        self.label = self.model['label']\n",
        "        self.name_c = self.model['name_c']\n",
        "        self.fs = self.model['fs']\n",
        "        st.write(\"Modelo cargado exitosamente.\")\n",
        "\n",
        "    def process_segment(self, audio_segment, fs):\n",
        "        \"\"\"Procesa el segmento de audio y calcula su espectro de frecuencias\"\"\"\n",
        "        st.write(\"Calculando la transformada de Fourier del segmento de audio...\")\n",
        "        # Remuestrear si es necesario\n",
        "        if fs != self.fs:\n",
        "            st.write(f\"Remuestreando el segmento a {self.fs} Hz...\")\n",
        "            num_samples = int(len(audio_segment) * self.fs / fs)\n",
        "            audio_segment = resample(audio_segment, num_samples)\n",
        "            fs = self.fs\n",
        "\n",
        "        # Calcular la transformada rápida de Fourier (rfft) para señal real\n",
        "        Xw_segment = np.abs(rfft(audio_segment)[:self.fmax])\n",
        "        Xw_segment /= np.max(Xw_segment)  # Normalizar\n",
        "        return Xw_segment\n",
        "\n",
        "    def recognize_genre(self, processed_segment):\n",
        "        \"\"\"Reconoce si la canción es metal o reguetón basándose en el espectro de frecuencias\"\"\"\n",
        "        st.write(\"Comparando el espectro del segmento con las canciones del modelo...\")\n",
        "        distances_metal = []\n",
        "        distances_reggaeton = []\n",
        "\n",
        "        for i, Xw_ref in enumerate(self.Xw_):\n",
        "            dist = np.linalg.norm(processed_segment - Xw_ref[:self.fmax])  # Distancia euclidiana\n",
        "\n",
        "            if self.label[i] == 1:  # Género 1: Metal\n",
        "                distances_metal.append(dist)\n",
        "            elif self.label[i] == 2:  # Género 2: Reguetón\n",
        "                distances_reggaeton.append(dist)\n",
        "\n",
        "        min_dist_metal = np.min(distances_metal)\n",
        "        min_dist_reggaeton = np.min(distances_reggaeton)\n",
        "\n",
        "        distances = np.array([min_dist_metal, min_dist_reggaeton])\n",
        "        probabilities = softmax(-distances)  # Aplicamos softmax a las distancias negativas\n",
        "\n",
        "        if probabilities[0] > probabilities[1]:\n",
        "            genre = \"Metal\"\n",
        "        else:\n",
        "            genre = \"Reguetón\"\n",
        "\n",
        "        return genre, probabilities\n",
        "\n",
        "# Clase para realizar la modulación AM\n",
        "class AMModulator:\n",
        "    def __init__(self, audio, fs, carrier_freq=10000, mod_index=1.0):\n",
        "        self.audio = audio\n",
        "        self.fs = fs\n",
        "        self.Ac = 1.0  # Amplitud de la portadora\n",
        "        self.Fc = carrier_freq  # Frecuencia de la portadora\n",
        "        self.mod_index = mod_index  # Índice de modulación ajustable\n",
        "        self.t = np.linspace(0, len(self.audio) / self.fs, len(self.audio), endpoint=False)  # Vector de tiempo\n",
        "\n",
        "    def generate_carrier(self, theta0=0):\n",
        "        \"\"\"Genera la señal portadora con fase θ0\"\"\"\n",
        "        self.carrier = self.Ac * np.cos(2 * np.pi * self.Fc * self.t + theta0)\n",
        "        return self.carrier\n",
        "\n",
        "    def modulate_am(self):\n",
        "        \"\"\"Realiza la modulación AM\"\"\"\n",
        "        self.generate_carrier()  # Generar la señal portadora\n",
        "        message_norm = self.audio / np.max(np.abs(self.audio))  # Normalizar la señal de mensaje\n",
        "        self.modulated_signal = (1 + self.mod_index * message_norm) * self.carrier\n",
        "        return self.modulated_signal\n",
        "\n",
        "    def demodulate_am(self):\n",
        "        \"\"\"Demodula la señal AM y aplica un filtro pasa bajas\"\"\"\n",
        "        received_signal = self.modulated_signal * self.carrier  # Multiplicar por la portadora\n",
        "\n",
        "        # Filtro pasa bajas (usando la Transformada Bilineal)\n",
        "        wc = 2 * np.pi * (self.Fc / 2) / self.fs\n",
        "        b_analog = [wc]\n",
        "        a_analog = [1, wc]\n",
        "        self.b_digital, self.a_digital = bilinear(b_analog, a_analog, self.fs)\n",
        "        self.demodulated_signal = lfilter(self.b_digital, self.a_digital, received_signal)\n",
        "        self.demodulated_signal *= (2 / self.Ac)  # Escalar la señal de demodulación\n",
        "        return self.demodulated_signal\n",
        "\n",
        "    def plot_signals(self):\n",
        "        \"\"\"Genera gráficos de las señales en el dominio del tiempo\"\"\"\n",
        "        plt.figure(figsize=(14, 10))\n",
        "\n",
        "        # Señal de Mensaje\n",
        "        plt.subplot(4, 1, 1)\n",
        "        plt.plot(self.t, self.audio)\n",
        "        plt.title('Señal de Mensaje (m(t))')\n",
        "        plt.xlabel('Tiempo [s]')\n",
        "        plt.ylabel('Amplitud')\n",
        "\n",
        "        # Señal Portadora\n",
        "        plt.subplot(4, 1, 2)\n",
        "        plt.plot(self.t, self.carrier)\n",
        "        plt.title(f'Señal Portadora (c(t)) con frecuencia {self.Fc} Hz')\n",
        "        plt.xlabel('Tiempo [s]')\n",
        "        plt.ylabel('Amplitud')\n",
        "\n",
        "        # Señal Modulada AM\n",
        "        plt.subplot(4, 1, 3)\n",
        "        plt.plot(self.t, self.modulated_signal)\n",
        "        plt.title(f'Señal Modulada AM con índice {self.mod_index}')\n",
        "        plt.xlabel('Tiempo [s]')\n",
        "        plt.ylabel('Amplitud')\n",
        "\n",
        "        # Señal Demodulada AM\n",
        "        plt.subplot(4, 1, 4)\n",
        "        plt.plot(self.t, self.demodulated_signal)\n",
        "        plt.title('Señal Demodulada AM')\n",
        "        plt.xlabel('Tiempo [s]')\n",
        "        plt.ylabel('Amplitud')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(plt)\n",
        "\n",
        "    def plot_frequency_domain(self, signal, title=\"Espectro de Frecuencia\"):\n",
        "        \"\"\"Genera la gráfica del espectro de frecuencia\"\"\"\n",
        "        fft_data = rfft(signal)\n",
        "        freqs = rfftfreq(len(signal), 1/self.fs)\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(freqs, np.abs(fft_data))\n",
        "        plt.title(title)\n",
        "        plt.xlabel('Frecuencia [Hz]')\n",
        "        plt.ylabel('Magnitud')\n",
        "        plt.grid()\n",
        "        st.pyplot(plt)\n",
        "\n",
        "    def save_audio_signals(self):\n",
        "        \"\"\"Guarda las señales de mensaje, modulada y demodulada en buffers para reproducir en Streamlit\"\"\"\n",
        "        audio_buffer_message = io.BytesIO()\n",
        "        audio_buffer_modulated = io.BytesIO()\n",
        "        audio_buffer_demodulated = io.BytesIO()\n",
        "        audio_buffer_filtered = io.BytesIO()  # Añadir buffer para señal filtrada\n",
        "\n",
        "        # Guardar las señales\n",
        "        sf.write(audio_buffer_message, self.audio, self.fs, format='WAV')\n",
        "        sf.write(audio_buffer_modulated, self.modulated_signal, self.fs, format='WAV')\n",
        "        sf.write(audio_buffer_demodulated, self.demodulated_signal, self.fs, format='WAV')\n",
        "        sf.write(audio_buffer_filtered, self.demodulated_signal, self.fs, format='WAV')  # Señal filtrada\n",
        "\n",
        "        # Devolver los buffers para reproducción en Streamlit\n",
        "        audio_buffer_message.seek(0)\n",
        "        audio_buffer_modulated.seek(0)\n",
        "        audio_buffer_demodulated.seek(0)\n",
        "        audio_buffer_filtered.seek(0)  # Retorna también la señal filtrada\n",
        "\n",
        "        return audio_buffer_message, audio_buffer_modulated, audio_buffer_demodulated, audio_buffer_filtered\n",
        "\n",
        "    def plot_lpf_response(self):\n",
        "        \"\"\"Muestra la respuesta en frecuencia del filtro Pasa Bajas\"\"\"\n",
        "        w, h = freqz(self.b_digital, self.a_digital, fs=self.fs)\n",
        "        plt.figure()\n",
        "        plt.plot(w, 20 * np.log10(abs(h)))\n",
        "        plt.title('Respuesta en Frecuencia del Filtro Pasa Bajas')\n",
        "        plt.xlabel('Frecuencia [Hz]')\n",
        "        plt.ylabel('Amplitud [dB]')\n",
        "        plt.grid()\n",
        "        st.pyplot(plt)\n",
        "\n",
        "    def plot_poles_zeros(self):\n",
        "        \"\"\"Muestra el diagrama de polos y ceros del filtro Pasa Bajas\"\"\"\n",
        "        z, p, k = signal.tf2zpk(self.b_digital, self.a_digital)\n",
        "        plt.figure()\n",
        "        plt.scatter(np.real(z), np.imag(z), marker='o', label='Ceros')\n",
        "        plt.scatter(np.real(p), np.imag(p), marker='x', label='Polos')\n",
        "        plt.title('Diagrama de Polos y Ceros')\n",
        "        plt.xlabel('Parte Real')\n",
        "        plt.ylabel('Parte Imaginaria')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        st.pyplot(plt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Streamlit App\n",
        "def main():\n",
        "    # Simulación de Sistema Masa-Resorte-Amortiguador\n",
        "    st.title(\"Simulación de Sistema Masa-Resorte-Amortiguador y su equivalente RLC\")\n",
        "\n",
        "    st.write(\"\"\"\n",
        "    ### Sistema Masa-Resorte-Amortiguador:\n",
        "    Esta aplicación interactiva permite simular un sistema masa-resorte-amortiguador y su equivalente en términos de un circuito **RLC**.\n",
        "    Use las barras deslizantes para ajustar los valores de la masa, amortiguamiento y constante del resorte y observar las respuestas del sistema.\n",
        "    \"\"\")\n",
        "\n",
        "    # Inputs de usuario con barras deslizantes\n",
        "    m = st.slider(\"Masa (m) [kg]\", min_value=0.1, max_value=10.0, value=1.0, step=0.1)\n",
        "    c = st.slider(\"Amortiguamiento (c) [Ns/m]\", min_value=0.0, max_value=10.0, value=0.5, step=0.1)\n",
        "    k = st.slider(\"Constante del Resorte (k) [N/m]\", min_value=0.1, max_value=20.0, value=2.0, step=0.1)\n",
        "\n",
        "    # Calcular los valores equivalentes del circuito RLC\n",
        "    L, R, C = calcular_equivalente_RLC(m, c, k)\n",
        "\n",
        "    # Simulación cuando el usuario presiona el botón\n",
        "    if st.button(\"Simular Sistema\"):\n",
        "        # Obtener las respuestas del sistema\n",
        "        w, mag, phase, t_step, step_response, t_impulse, impulse_response = simular_sistema_masa_resorte(m, c, k)\n",
        "\n",
        "        # Mostrar los resultados\n",
        "        st.write(f\"**Parámetros Ingresados:**\")\n",
        "        st.write(f\"- Masa (m): {m} kg\")\n",
        "        st.write(f\"- Amortiguamiento (c): {c} Ns/m\")\n",
        "        st.write(f\"- Constante del Resorte (k): {k} N/m\")\n",
        "\n",
        "        # Mostrar los valores equivalentes del circuito RLC\n",
        "        st.write(\"**Equivalente RLC:**\")\n",
        "        st.write(f\"- Inductancia (L): {L:.2f} H\")\n",
        "        st.write(f\"- Resistencia (R): {R:.2f} Ω\")\n",
        "        st.write(f\"- Capacitancia (C): {C:.4f} F\")\n",
        "\n",
        "        # Graficar resultados\n",
        "        graficar_resultados(w, mag, phase, t_step, step_response, t_impulse, impulse_response)\n",
        "\n",
        "    # Descarga y reconocimiento de género musical desde YouTube\n",
        "    st.title(\"Descarga y reconocimiento de género musical desde YouTube\")\n",
        "\n",
        "    # Ingresar enlace de YouTube y tiempos de segmentación\n",
        "    link_audio = st.text_input(\"Ingrese el enlace de YouTube:\", \"https://www.youtube.com/watch?v=51cZsDsVOqc\")\n",
        "    tiempo_inicio = st.slider(\"Tiempo de inicio del segmento (segundos):\", min_value=0, max_value=60, value=30)\n",
        "    tiempo_fin = st.slider(\"Tiempo de fin del segmento (segundos):\", min_value=1, max_value=120, value=120)\n",
        "    frecuencia_deseada = st.slider(\"Frecuencia de muestreo deseada (Hz):\", min_value=8000, max_value=48000, value=48000)\n",
        "\n",
        "    # Crear una instancia del descargador de audio\n",
        "    downloader = AudioDownloader(link=link_audio)\n",
        "\n",
        "    if st.button(\"Descargar y procesar audio\"):\n",
        "        try:\n",
        "            # Paso 1: Descargar y convertir el audio desde YouTube\n",
        "            downloader.download_audio()\n",
        "\n",
        "            # Paso 2: Cargar el archivo de audio y remuestrearlo si es necesario\n",
        "            audio, fs = downloader.load_audio(target_fs=frecuencia_deseada)\n",
        "\n",
        "            # Paso 3: Segmentar el audio basado en la selección del usuario\n",
        "            segmento, fs = downloader.segment_audio(start_time=tiempo_inicio, end_time=tiempo_fin)\n",
        "\n",
        "            # Guardar el segmento en un buffer temporal\n",
        "            audio_buffer = io.BytesIO()\n",
        "            sf.write(audio_buffer, segmento, fs, format='WAV')\n",
        "            audio_buffer.seek(0)\n",
        "\n",
        "            # Reproducir el fragmento de audio seleccionado\n",
        "            st.audio(audio_buffer, format=\"audio/wav\")\n",
        "\n",
        "            # Cargar el modelo de canciones (contiene espectros de metal y reguetón)\n",
        "            model_path = \"modelo/reggaeton_vs_metal.pkl\"\n",
        "            my_model_loaded = joblib.load(model_path)\n",
        "            recognizer = AudioRecognizer(my_model_loaded)\n",
        "\n",
        "            # Paso 4: Procesar el segmento de audio\n",
        "            processed_segment = recognizer.process_segment(segmento, fs)\n",
        "\n",
        "            # Paso 5: Reconocer el género de la canción y las probabilidades\n",
        "            genre, probabilities = recognizer.recognize_genre(processed_segment)\n",
        "\n",
        "            # Mostrar el resultado\n",
        "            st.write(f\"La canción es más probable que sea del género: {genre}\")\n",
        "            st.write(f\"Probabilidad de Metal: {probabilities[0] * 100:.2f}%\")\n",
        "            st.write(f\"Probabilidad de Reguetón: {probabilities[1] * 100:.2f}%\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error al procesar el audio: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Simulación de Modulación AM y Demodulación\n",
        "    st.title(\"Simulación de Modulación AM y Demodulación\")\n",
        "\n",
        "\n",
        "    # Usa el segmento de audio descargado y procesado\n",
        "    if 'segmento' not in locals():\n",
        "        st.error(\"Debe descargar y procesar el audio antes de proceder con la modulación AM.\")\n",
        "        return\n",
        "\n",
        "    # Parámetros de modulación\n",
        "    mod_index = st.slider(\"Índice de modulación\", min_value=0.1, max_value=2.0, value=1.0, step=0.1)\n",
        "    carrier_freq = st.slider(\"Frecuencia de la portadora (Hz)\", min_value=1000, max_value=48000, value=48000, step=1000)\n",
        "\n",
        "    # Crear instancia del modulador\n",
        "    modulator = AMModulator(audio=segmento, fs=fs, carrier_freq=carrier_freq, mod_index=mod_index)\n",
        "\n",
        "    # Paso 1: Realizar la modulación AM\n",
        "    modulated_signal = modulator.modulate_am()\n",
        "\n",
        "    # Paso 2: Realizar la demodulación AM\n",
        "    demodulated_signal = modulator.demodulate_am()\n",
        "\n",
        "    # Paso 3: Mostrar gráficos de las señales\n",
        "    st.write(\"### Gráficos de las señales en el tiempo:\")\n",
        "    modulator.plot_signals()\n",
        "\n",
        "    # Mostrar señales en el dominio de la frecuencia\n",
        "    st.write(\"### Espectro de frecuencia:\")\n",
        "    modulator.plot_frequency_domain(segmento, title=\"Espectro del Mensaje (m(t))\")\n",
        "    modulator.plot_frequency_domain(modulated_signal, title=\"Espectro de la Señal Modulada AM\")\n",
        "    modulator.plot_frequency_domain(demodulated_signal, title=\"Espectro de la Señal Demodulada AM\")\n",
        "\n",
        "    # Mostrar respuesta del filtro pasa bajas y polos/ceros\n",
        "    st.write(\"### Respuesta del Filtro Pasa Bajas:\")\n",
        "    modulator.plot_lpf_response()\n",
        "\n",
        "    st.write(\"### Diagrama de Polos y Ceros del Filtro Pasa Bajas:\")\n",
        "    modulator.plot_poles_zeros()\n",
        "\n",
        "    # Guardar y reproducir las señales\n",
        "    audio_buffer_message, audio_buffer_modulated, audio_buffer_demodulated, audio_buffer_filtered = modulator.save_audio_signals()\n",
        "\n",
        "    # Reproducir las señales\n",
        "    st.write(\"### Reproducción de la señal de mensaje (m(t)):\")\n",
        "    st.audio(audio_buffer_message, format=\"audio/wav\")\n",
        "\n",
        "    st.write(\"### Reproducción de la señal modulada AM:\")\n",
        "    st.audio(audio_buffer_modulated, format=\"audio/wav\")\n",
        "\n",
        "    st.write(\"### Reproducción de la señal demodulada AM (filtrada):\")\n",
        "    st.audio(audio_buffer_filtered, format=\"audio/wav\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxXGfU4z21Yt",
        "outputId": "16df473a-ab9c-4e8c-e608-4917b6476fe8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parcial3_dashboard.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como al momento de correr el script con Streamlit se requiere del archivo .py donde se encuentre el código, utilizamos %%writefile para crearlo. Posteriormente hacemos toda la configuración de Ngrok con el token y demás datos de protocolo."
      ],
      "metadata": {
        "id": "Wmhs3tByoErw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token = '2loY5BE5ZxQ3TstzfOMcpiGVm5q_4wkwQQXBRgu5GmePE82kL' #colocar aquí su token personal después de crear su cuenta con correo UNAL en Ngrok"
      ],
      "metadata": {
        "id": "BFoInA_Fo7ut"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_dnnaHgfJdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set authentication token (unique per user)\n",
        "ngrok.set_auth_token(token)\n",
        "\n",
        "# Start Streamlit server on a specific port\n",
        "!nohup streamlit run parcial3_dashboard.py --server.port 5011 &\n",
        "\n",
        "# Start ngrok tunnel to expose the Streamlit server\n",
        "ngrok_tunnel = ngrok.connect(addr='5011', proto='http', bind_tls=True)\n",
        "\n",
        "# Print the URL of the ngrok tunnel\n",
        "print(' * Tunnel URL:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owu5b-ENhQuZ",
        "outputId": "7e8bad50-73f8-4b5a-fa00-10073f266fab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            " * Tunnel URL: https://3ee7-35-221-194-49.ngrok-free.app\n"
          ]
        }
      ]
    }
  ]
}